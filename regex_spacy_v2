{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOs5oqNUckwd8jgZdbZjKNh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Regex-Spcy Hybrid Model v2\n","##### Included in this script is a regex & Spacy hybrid PII detection model that:\n","##### 1) Takes in the Kaggle NER dataset and processes it into a dataframe. (https://www.kaggle.com/datasets/namanj27/ner-dataset?select=ner_datasetreference.csv)\n","##### 2) Runs the data through the PII detection techniques. \n","##### 3) Maps the output of the detection model (as Spacy and Kaggle did not use the same categories)\n","##### 4) Measures the success of the model's predictions against the actual, using Precision, Recall, and F-1 Score. \n"],"metadata":{"id":"UkziWEqtQ4Ao"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BMkfiY9pRCQh","executionInfo":{"status":"ok","timestamp":1679118417665,"user_tz":240,"elapsed":1074,"user":{"displayName":"Dream Phoenix","userId":"09226332887600260845"}},"outputId":"6efa73b6-ba40-440d-b596-3743c8932cac"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Copy the Kaggle NER dataset\n","!cp /content/drive/MyDrive/EDAs/ner_datasetreference.csv /content/"],"metadata":{"id":"lkLhp2P3RzGV","executionInfo":{"status":"ok","timestamp":1679118427959,"user_tz":240,"elapsed":367,"user":{"displayName":"Dream Phoenix","userId":"09226332887600260845"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load dataset\n","data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\").fillna(method=\"ffill\")\n","\n","# Preprocess dataset\n","agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(), s[\"POS\"].values.tolist(), s[\"Tag\"].values.tolist())]\n","grouped = data.groupby(\"Sentence #\").apply(agg_func)\n","sentences = [s for s in grouped]\n","\n","# Create a dataframe from the processed dataset\n","processed_data = []\n","\n","for sentence in sentences:\n","    for w, p, t in sentence:\n","        processed_data.append({\"Word\": w, \"POS\": p, \"Tag\": t})\n","\n","processed_df = pd.DataFrame(processed_data)\n","\n","# Show the first five rows of the dataframe\n","print(processed_df.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vMgwHEO2PwB4","executionInfo":{"status":"ok","timestamp":1679118445354,"user_tz":240,"elapsed":15030,"user":{"displayName":"Dream Phoenix","userId":"09226332887600260845"}},"outputId":"43300e1c-6b19-4048-c19f-04dfa39ef0aa"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["            Word  POS Tag\n","0      Thousands  NNS   O\n","1             of   IN   O\n","2  demonstrators  NNS   O\n","3           have  VBP   O\n","4        marched  VBN   O\n"]}]},{"cell_type":"code","source":["import re\n","import spacy\n","from spacy import displacy\n","\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","patterns = {\n","    \"ORGANIZATION\": r\"[A-Z][a-z]+\\s(?:[A-Z][a-z]*\\s?)+\",\n","    \"PERSON\": r\"[A-Z][a-z]+\\s[A-Z][a-z]+\",\n","    \"LOCATION\": r\"[A-Z][a-z]+(?:\\s[A-Z][a-z]+)?\",\n","    \"DATE\": r\"\\b(?:\\d{1,2}\\s)?(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*(?:-|\\.|\\s)\\d{1,2}(?:-|,|\\s)\\d{2,4}\\b\",\n","    \"TIME\": r\"\\d{1,2}:\\d{2}\\s?(?:a\\.?m\\.?|p\\.?m\\.?)?\",\n","    \"MONEY\": r\"(?:\\$|£|€)\\d+(?:\\.\\d{1,2})?\",\n","    \"PERCENT\": r\"\\d+\\.?\\d*\\s?%\",\n","    \"FACILITY\": r\"[A-Z][a-z]+\\s(?:[A-Z][a-z]*\\s?)+\",\n","    \"GPE\": r\"[A-Z][a-z]+(?:\\s[A-Z][a-z]+)?\",\n","}\n","\n","def regex_entities(text, patterns):\n","    entities = []\n","    for label, pattern in patterns.items():\n","        for match in re.finditer(pattern, text):\n","            start, end = match.span()\n","            entities.append((start, end, label))\n","    return entities\n","\n","regex_spacy_results = []\n","\n","for sentence in sentences:\n","    text = \" \".join([w[0] for w in sentence])\n","    true_entities = [(w[0], w[2]) for w in sentence if w[2] != \"O\"]\n","\n","    # Find entities using regex\n","    regex_entities_found = regex_entities(text, patterns)\n","\n","    # Find entities using SpaCy\n","    doc = nlp(text)\n","    spacy_entities_found = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n","\n","    # Combine regex and SpaCy entities without duplicates\n","    combined_entities = list(set(regex_entities_found + spacy_entities_found))\n","\n","    for entity in combined_entities:\n","        start, end, label = entity\n","        word = text[start:end]\n","        regex_spacy_results.append({\"Word\": word, \"Tag\": label})\n","\n","# Create a dataframe from the regex and SpaCy results\n","regex_spacy_df = pd.DataFrame(regex_spacy_results)\n","\n","# Show the first five rows of the dataframe\n","print(regex_spacy_df.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DPOidOD3c_RA","executionInfo":{"status":"ok","timestamp":1679119135515,"user_tz":240,"elapsed":610200,"user":{"displayName":"Dream Phoenix","userId":"09226332887600260845"}},"outputId":"56b9238a-5f07-42f2-e91b-30a83aff8984"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n"]},{"output_type":"stream","name":"stdout","text":["        Word       Tag\n","0    British      NORP\n","1  Thousands       GPE\n","2     London       GPE\n","3  Thousands  LOCATION\n","4     London  LOCATION\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Define the mapping function\n","def map_spacy_to_kaggle_labels(spacy_label):\n","    mapping = {\n","        'ORG': 'ORGANIZATION',\n","        'PERSON': 'PERSON',\n","        'LOC': 'LOCATION',\n","        'DATE': 'DATE',\n","        'TIME': 'TIME',\n","        'MONEY': 'MONEY',\n","        'PERCENT': 'PERCENT',\n","        'FAC': 'FACILITY',\n","        'GPE': 'GPE'\n","    }\n","    \n","    return mapping.get(spacy_label, spacy_label)\n","\n","# Apply the mapping function to the predicted labels in the regex_spacy_df\n","regex_spacy_df['predicted_kaggle_label'] = regex_spacy_df['Tag'].apply(map_spacy_to_kaggle_labels)\n","\n","# Merge the two dataframes\n","merged_df = pd.merge(processed_df, regex_spacy_df, on='Word', how='left')\n","merged_df.drop(columns=['Tag'], inplace=True)\n","\n","print(merged_df.head())\n"],"metadata":{"id":"n3LVvzliPXNr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","# Extract actual and predicted labels\n","true_labels = final_df['actual_label'].tolist()\n","pred_labels = final_df['predicted_kaggle_label'].tolist()\n","\n","# Calculate and print the classification report\n","print(classification_report(true_labels, pred_labels, digits=4))\n"],"metadata":{"id":"Dm6zA55MQv3j","executionInfo":{"status":"ok","timestamp":1679119303546,"user_tz":240,"elapsed":195,"user":{"displayName":"Dream Phoenix","userId":"09226332887600260845"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"si-99qqNAGT9"},"execution_count":null,"outputs":[]}]}